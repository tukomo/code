<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ML Code Snippets</title>
    <style>
        body {
            font-family: sans-serif;
            line-height: 1.6;
            margin: 20px;
            background-color: #f4f4f4;
            color: #333;
        }
        .container {
            max-width: 800px;
            margin: auto;
            overflow: auto;
            padding: 0 20px;
        }
        .code-block {
            background: #fff;
            padding: 20px;
            margin-bottom: 20px;
            border-radius: 5px;
            position: relative;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        h1, h2 {
            color: #333;
        }
        pre {
            background: #eee;
            padding: 15px;
            border-radius: 5px;
            white-space: pre-wrap;
            word-wrap: break-word;
            font-family: "Courier New", Courier, monospace;
        }
        .copy-btn {
            position: absolute;
            top: 20px;
            right: 20px;
            background: #4CAF50; /* Green for ML section */
            color: #fff;
            border: none;
            padding: 8px 12px;
            border-radius: 5px;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }
        .copy-btn:hover {
            background: #45a049;
        }
        .home-btn {
            display: inline-block;
            margin-bottom: 20px;
            background: #555;
            color: #fff;
            padding: 10px 15px;
            text-decoration: none;
            border-radius: 5px;
        }
        .home-btn:hover {
            background: #333;
        }
    </style>
</head>
<body>

    <div class="container">
        <a href="index.html" class="home-btn">Back to Home</a>
        <h1>ML Python Code Snippets</h1>

        <div class="code-block">
            <h2>Installation</h2>
            <p>To run these snippets, you need to install the following Python libraries. You can install them all with this command:</p>
            <pre><code>pip install pandas numpy scikit-learn matplotlib seaborn plotly wordcloud networkx statsmodels pydotplus</code></pre>
        </div>

        <div class="code-block">
            <h2>Program 1: Pandas Data Exploration</h2>
            <button class="copy-btn" onclick="copyToClipboard(event, 'code1')">Copy</button>
            <pre id="code1"><code>
import pandas as pd

df = pd.read_csv("/content/empdata.csv")
print(df.head())

print(df.shape)

df[: : 2]

df.columns

total_sum = df.isna().sum().sum()
print(total_sum)

df1 = pd.concat([df,df])
print(df.shape)
print(df1.shape)

df1 = df1.drop_duplicates()
df1.shape

df.columns = [i.upper() for i in df]
print(df.columns)

print(df.notnull())

print('The no. of nulls in each column is \n',df1.isna().sum())

print('Highest Salary is',df['SALARY'].max())
print('Lowest Salary is', df['SALARY'].min())

df[df.SALARY > 20000]

df[['EMPID','ENAME']] [df.SALARY == df.SALARY.max()]
            </code></pre>
        </div>

        <div class="code-block">
            <h2>Program 2: Data Preprocessing Pipeline</h2>
            <button class="copy-btn" onclick="copyToClipboard(event, 'code2')">Copy</button>
            <pre id="code2"><code>
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

data= {
    'Age': [25, 30, np.nan, 40, 35],
    'Salary': [50000, 60000, 55000, np.nan, 65000],
    'Department': ['HR', 'IT', 'Finance', 'IT', np.nan],
    'Purchased': ['Yes', 'No', 'Yes', 'No', 'Yes']
}

df=pd.DataFrame(data)
print("Original Data:")
print(df)

X=df.drop('Purchased',axis=1)
y=df['Purchased']

num_features=['Age','Salary']
cat_features=['Department']

num_pipeline=Pipeline(steps=[
    ('imputer',SimpleImputer(strategy='mean')),
    ('scaler',StandardScaler())
])

cat_pipeline=Pipeline(steps=[
    ('imputer',SimpleImputer(strategy='most_frequent')),
  ('encoder',OneHotEncoder(handle_unknown='ignore'))
])

preprocessor= ColumnTransformer(
    transformers= [
        ('num', num_pipeline, num_features),
        ('cat', cat_pipeline, cat_features)
    ])

X_clean=preprocessor.fit_transform(X)

feature_names = num_features + list(
    preprocessor.named_transformers_['cat']['encoder'].get_feature_names_out(cat_features)
)

X_clean_df=pd.DataFrame(
    X_clean.toarray() if hasattr(X_clean,"toarray") else X_clean,
    columns = feature_names
)

print("\nCleaned and Transformed Data:")
print(X_clean_df)

X_train, X_test, y_train, y_test = train_test_split(X_clean_df, y, test_size=0.2, random_state=42)

print("\nTrain Data:")
print(X_train)
            </code></pre>
        </div>

        <div class="code-block">
            <h2>Program 3: Data Visualization</h2>
            <button class="copy-btn" onclick="copyToClipboard(event, 'code3')">Copy</button>
            <pre id="code3"><code>
import matplotlib.pyplot as plt

x = [1 , 2, 3, 4, 5]
y = [2, 5, 7, 1, 6]

plt.plot(x,y,marker='x', linestyle= 'dotted')
plt.title("Line Plot")
plt.xlabel("X Axis")
plt.ylabel("Y Axis")
plt.grid(True)
plt.show()

x = ["A", "B", "C", "D"]
y = [3, 1, 7, 10]

plt.xlabel("X Axis")
plt.ylabel("Y Axis")
plt.bar(x,y,color="yellow")
plt.title("Bar Plot")
plt.show()

import numpy as np

data = np.random.randn(1000)
plt.hist(data,bins=50,color='blue',alpha=0.5)
plt.xlabel("X Axis")
plt.ylabel("Y Axis")
plt.title("Histogram")
plt.show()

x = [5,2,5,1,2,3,5,7,9]
y = [7,2,9,6,5,8,4,3,2]

plt.scatter(x, y)
plt.xlabel("X Axis")
plt.ylabel("Y Axis")
plt.show()

import seaborn as sns

tips=sns.load_dataset("tips")
sns.boxplot(x="day",y="total_bill",data=tips)
plt.title("Box plot with seaborn")
plt.show()

numerical_tips = tips.select_dtypes(include=['number'])
sns.heatmap(numerical_tips.corr(),annot=True,cmap="coolwarm")
plt.title("Heatmap(tips) with seaborn")
plt.show()

import seaborn as sns

iris=sns.load_dataset("iris")
sns.boxplot(x="species",y="sepal_length",data=iris)
plt.title("Box plot with seaborn")
plt.show()

numerical_data = iris.select_dtypes(include=["float","int"])
sns.heatmap(numerical_tips.corr(),annot=True,cmap="coolwarm")
plt.title("Heatmap(Iris) with seaborn")
plt.show()

import  plotly.express as px
df=px.data.iris()
fig=px.scatter(df,x="sepal_width",y="sepal_length",color="species",size="petal_length",hover_data=["petal_width"])
fig.show()

df=px.data.stocks()
fig=px.line(df,x="date",y=["GOOG","AAPL","AMZN"],title="Stock Prices")
fig.show()

from wordcloud import WordCloud

text = "Python for V DS B Visulaization Tate Human and Child Trafficking Brainrot Advanced Methods Python Python Seaborn Saber Matplotlib AI AI, So Sigma"
wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)

plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.show()

import networkx as nx

G = nx.karate_club_graph()
nx.draw(G, with_labels=True, node_color="black", node_size=500, font_size=10, font_color="white")
plt.show()
            </code></pre>
        </div>

        <div class="code-block">
            <h2>Program 4: Simple Linear Regression</h2>
            <button class="copy-btn" onclick="copyToClipboard(event, 'code4')">Copy</button>
            <pre id="code4"><code>
import pandas as pd
import statsmodels.api as sm
from sklearn.model_selection import train_test_split

mba_salary_df = pd.read_csv('/content/MBA Salary.csv')
mba_salary_df.head(3)

mba_salary_df.info()

X = sm.add_constant(mba_salary_df['Percentage in Grade 10'])
X.head(5)

Y = mba_salary_df['Salary']
Y.head()

from sklearn.model_selection import train_test_split
train_X,test_X,train_y,test_y=train_test_split(X,Y,train_size=0.8,random_state=100)

mba_salary_lm=sm.OLS(train_y,train_X).fit()

print(mba_salary_lm.params)

print(mba_salary_lm.summary2())

import matplotlib.pyplot as plt
def get_std_values(vals):
    return(vals - vals.mean())/vals.std()
x_axis = get_std_values(mba_salary_lm.fittedvalues)
y_axis = get_std_values(mba_salary_lm.resid)
plt.scatter(x_axis, y_axis)
plt.xlabel("Standardised Predicted values")
plt.ylabel("Standardised Residual Values")
plt.title("Residual Plot")
plt.show()

from scipy.stats import zscore
mba_salary_df['z_score_salary'] = zscore(mba_salary_df.Salary)
mba_salary_df[(mba_salary_df.z_score_salary > 3.0)| (mba_salary_df.z_score_salary< -3.0)]

import numpy as np
mba_influence = mba_salary_lm.get_influence()
(c,p) = mba_influence.cooks_distance

import numpy as np
from sklearn.metrics import r2_score, mean_squared_error
pred_y = mba_salary_lm.predict(test_X)
print('R2 Score =',np.abs(r2_score(test_y,pred_y)))
print('RMSE = ', np.sqrt(mean_squared_error(test_y,pred_y)))

plt.stem(np.arange(len(train_X)), np.round(c,3))
plt.xlabel("Row Index")
plt.ylabel("Cooks Distance")
plt.show()

import matplotlib.pyplot as plt
plt.scatter(X_test['Percentage in Grade 10'],Y_test,color='red',label="Actual")
plt.plot(X_test['Percentage in Grade 10'],pred_y,color='blue',label="Predicted")
plt.xlabel('Percentage in Grade 10')
plt.ylabel('Salary')
plt.title('Actual vs Predicted')
plt.legend()
plt.show()
            </code></pre>
        </div>

        <div class="code-block">
            <h2>Program 5: Logistic Regression</h2>
            <button class="copy-btn" onclick="copyToClipboard(event, 'code5')">Copy</button>
            <pre id="code5"><code>
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, roc_auc_score

df = pd.read_csv('/content/abc.csv')
features = ['male', 'age', 'education', 'currentSmoker', 'cigsPerDay',
            'BPMeds', 'prevalentStroke', 'prevalentHyp', 'diabetes',
            'totChol', 'sysBP', 'diaBP', 'BMI', 'heartRate', 'glucose']
X = df[features]
y = df['TenYearCHD']

X.fillna(X.mean(), inplace=True)

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

model = LogisticRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
y_pred_proba = model.predict_proba(X_test)[:, 1]

print("Classification Report:")
print(classification_report(y_test, y_pred))
print("AUC-ROC Score:", roc_auc_score(y_test, y_pred_proba))

import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc
y_pred_proba = model.predict_proba(X_test)[:, 1]
fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC Curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for Logistic Regression')
plt.legend(loc='lower right')
plt.show()

coefficients = model.coef_[0]
feature_names = features
plt.figure(figsize=(10, 6))
plt.barh(feature_names, coefficients)
plt.xlabel('Coefficient Value')
plt.title('Feature Importance in Logistic Regression')
plt.show()
            </code></pre>
        </div>

        <div class="code-block">
            <h2>Program 6: Naive Bayes Classifier</h2>
            <button class="copy-btn" onclick="copyToClipboard(event, 'code6')">Copy</button>
            <pre id="code6"><code>
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import confusion_matrix, classification_report
import pandas as pd

iris = load_iris()
x,y=iris.data,iris.target
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.5,random_state=42)

nb=GaussianNB()
nb.fit(x_train,y_train)

y_pred=nb.predict(x_test)

print("prediction was ===")
for i in range(len(y_test)):
  if(y_test[i]==y_pred[i]):
    print(f"Correct -> Sample [i]: Predicted = {iris.target_names[y_pred[i]]}, Actual = {iris.target_names[y_test[i]]}")
  else:
    print(f"Wrong -> Sample [i]: Predicted = {iris.target_names[y_pred[i]]}, Actual = {iris.target_names[y_test[i]]}")
accuracy=(y_pred == y_test).mean()
print(f"\nAccuracy: {accuracy:.2f}")

cm=confusion_matrix(y_test,y_pred)
cm_df=pd.DataFrame(cm,index=iris.target_names,columns=iris.target_names)
print("\n=== Confusion Matrix:")
print(cm_df)

print("\n=== Classification Report ===")
print(classification_report(y_test,y_pred,target_names=iris.target_names))
            </code></pre>
        </div>

        <div class="code-block">
            <h2>Program 7: K-Nearest Neighbors</h2>
            <button class="copy-btn" onclick="copyToClipboard(event, 'code7')">Copy</button>
            <pre id="code7"><code>
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
iris = load_iris()
x = iris.data
y = iris.target
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=47)
knn=KNeighborsClassifier(n_neighbors=3)
knn.fit(x_train, y_train)
y_pred = knn.predict(x_test)
print("Correct Predictions:")
for i in range(len(y_test)):
    if y_test[i] == y_pred[i]:
        print(f"Sample {i} : Predicted = {iris.target_names[y_pred[i]]}, Actual = {iris.target_names[y_test[i]]}")
print("\n Wrong Prediction:")
for i in range(len(y_test)):
    if y_test[i] != y_pred[i]:
        print(f"Sample {i} : Predicted = {iris.target_names[y_pred[i]]}, Actual = {iris.target_names[y_test[i]]}")
print("\n Accuracy:", knn.score(x_test, y_test))
            </code></pre>
        </div>

        <div class="code-block">
            <h2>Program 8: Decision Tree Classifier</h2>
            <button class="copy-btn" onclick="copyToClipboard(event, 'code8')">Copy</button>
            <pre id="code8"><code>
import pandas as pd
df=pd.read_csv('/content/German Credit Data (1).csv')
df.info()
df.shape
df.head()
df.iloc[0:5,0:7]
df.iloc[0:5,7:15]
df['checkin_acc'].unique()
X_features=list(df.columns)
X_features.remove('status')
encoded_df=pd.get_dummies(df[X_features],drop_first=True)
print(list(encoded_df.columns))
X=encoded_df
y=df['status']
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)
from sklearn.tree import DecisionTreeClassifier
clf=DecisionTreeClassifier(criterion='gini',max_depth=3)
clf.fit(X_train,y_train)
pred_y=clf.predict(X_test)
from sklearn import metrics
print("Confusion Matrix is\n",metrics.confusion_matrix(pred_y,y_test))
print("Accuracy is",metrics.accuracy_score(pred_y,y_test))
print("AUC Score is",metrics.roc_auc_score(pred_y,y_test))
#visualize using pyplot
from sklearn import tree
import matplotlib.pyplot as plt
plt.figure(figsize=(15,10))
tree.plot_tree(clf,filled=True,feature_names=X_train.columns,class_names=['Class 0','Class 1'])
plt.show()
            </code></pre>
        </div>

        <div class="code-block">
            <h2>Program 9: Random Forest Embedding + KMeans</h2>
            <button class="copy-btn" onclick="copyToClipboard(event, 'code9')">Copy</button>
            <pre id="code9"><code>
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_blobs
from sklearn.ensemble import RandomTreesEmbedding
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
X,y_true=make_blobs(n_samples=300,centers=3,cluster_std=0.60,random_state=42)
embedder=RandomTreesEmbedding(n_estimators=100,random_state=42)
X_transformed=embedder.fit_transform(X)
kmeans=KMeans(n_clusters=3,random_state=42)
y_kmeans=kmeans.fit_predict(X_transformed)
pca=PCA(n_components=2)
X_pca=pca.fit_transform(X_transformed.toarray())
plt.scatter(X_pca[:, 0],X_pca[:, 1],c=y_kmeans, cmap='rainbow', s=30)
plt.title("Clustering using Random Forest Embedding + KMeans")
plt.xlabel("PCA Component 1")
plt.ylabel("PCA Component 2")
plt.show()
            </code></pre>
        </div>

        <div class="code-block">
            <h2>Program 10: Support Vector Machine</h2>
            <button class="copy-btn" onclick="copyToClipboard(event, 'code10')">Copy</button>
            <pre id="code10"><code>
import numpy as np
import matplotlib.pyplot as plt
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix
iris = datasets.load_iris()
X=iris.data[:, :2]
y=iris.target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
scaler= StandardScaler()
X_train=scaler.fit_transform(X_train)
X_test=scaler.transform(X_test)
svm_model = SVC(kernel='linear', C=1.0, random_state=42)
svm_model.fit(X_train, y_train)
y_pred = svm_model.predict(X_test)
svm_model.fit(X_train, y_train)
print("Confusion Matrix: \n", confusion_matrix(y_test, y_pred))
print("Classification Report: \n", classification_report(y_test, y_pred))
def plot_svm(X,y, model):
    h = .02
    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
    np.arange(y_min, y_max, h))
    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])
    Z = Z.reshape(xx.shape)
    plt.contourf(xx, yy, Z, alpha=0.3)
    plt.scatter(X[:, 0], X[:, 1], c=y, s=30, edgecolors='k')
    plt.show()
plot_svm(X_train, y_train, svm_model)
            </code></pre>
        </div>

        <div class="code-block">
            <h2>Program 11: K-Means Clustering</h2>
            <button class="copy-btn" onclick="copyToClipboard(event, 'code11')">Copy</button>
            <pre id="code11"><code>
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
df = pd.read_csv('/content/Income Data.csv')
sns.lmplot(x="age",y="income",data=df,fit_reg=False,height=4)
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaled_df=scaler.fit_transform(df[["age","income"]])
scaled_df[0:5]
from sklearn.cluster import KMeans
clusters = KMeans(3)
clusters.fit(scaled_df)
df["clusterid"] = clusters.labels_
markers = ['+', '^', '*']
sns.lmplot(x="age",y="income",data= df, hue="clusterid", fit_reg=False, markers= markers, height=5)
clusters=KMeans(3)
clusters.fit(df)
df["new_clusterid"]=clusters.labels_
df.groupby("new_clusterid")[['age','income']].agg(["mean", 'std']).reset_index()
cluster_range = range(1,10)
cluster_errors = []
for num_clusters in cluster_range:
    clusters = KMeans(num_clusters)
    clusters.fit(scaled_df)
    cluster_errors.append(clusters.inertia_)
plt.figure(figsize=(6,4))
plt.plot(cluster_range, cluster_errors, marker = '*')
plt.xlabel('Number of clusters')
plt.ylabel('Sum of Squared Error')
plt.show()
            </code></pre>
        </div>
    </div>

    <script>
        function copyToClipboard(event, elementId) {
            const code = document.getElementById(elementId).innerText;
            const el = document.createElement('textarea');
            el.value = code;
            el.setAttribute('readonly', '');
            el.style.position = 'absolute';
            el.style.left = '-9999px';
            document.body.appendChild(el);
            el.select();
            document.execCommand('copy');
            document.body.removeChild(el);

            const button = event.target;
            const originalText = button.innerText;
            button.innerText = 'Copied!';
            setTimeout(() => {
                button.innerText = originalText;
            }, 1500);
        }
    </script>

</body>
</html>